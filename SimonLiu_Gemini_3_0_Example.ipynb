{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kY2dr9SG227S"
      },
      "source": [
        "# Gemini 3.0 Code Example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbVKHToe3Ihk"
      },
      "source": [
        "我是劉育維（Simon Liu），一名專注於人工智慧與機器學習（AI/ML）技術的工程師，擅長開發 AI 軟體服務應用。目前，我是 Google 開發者專家（GDE），專注於生成式人工智慧（GenAI）領域。曾成功為各產業提供 AI 技術架構規劃，助力企業加速數位轉型與創新。\n",
        "\n",
        "近兩年，我持續積極參與海內外技術社群，並累計發表超過 100 篇 AI 領域技術與實作相關文章。\n",
        "\n",
        "個人網站：https://simonliuyuwei.my.canva.site/link-in-bio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-ZYEJSJ2AEt"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q \"google\"\n",
        "!pip install -U -q \"google.genai\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8FWvPvX19-G"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from google.colab import drive\n",
        "os.environ[\"GEMINI_API_KEY\"] = userdata.get(\"GOOGLE_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_X2Cazh219-G"
      },
      "source": [
        "# Generated the answer by Gemini Model API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FzyAhQ6819-G"
      },
      "outputs": [],
      "source": [
        "# To run this code you need to install the following dependencies:\n",
        "# pip install google-genai\n",
        "\n",
        "import base64\n",
        "import os\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "\n",
        "def generate():\n",
        "    client = genai.Client(\n",
        "        api_key=os.environ.get(\"GEMINI_API_KEY\"),\n",
        "    )\n",
        "\n",
        "    model = \"gemini-3-pro-preview\" # @param [\"gemini-3.0-pro-preview\"]\n",
        "    user_text = \"\" # @param {type:\"string\"}\n",
        "\n",
        "    contents = [\n",
        "        types.Content(\n",
        "            role=\"user\",\n",
        "            parts=[\n",
        "                types.Part.from_text(text=user_text),\n",
        "            ],\n",
        "        ),\n",
        "    ]\n",
        "    generate_content_config = types.GenerateContentConfig(\n",
        "        thinking_config = types.ThinkingConfig(\n",
        "            thinking_budget=-1,\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    for chunk in client.models.generate_content_stream(\n",
        "        model=model,\n",
        "        contents=contents,\n",
        "        config=generate_content_config,\n",
        "    ):\n",
        "        print(chunk.text, end=\"\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    generate()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
